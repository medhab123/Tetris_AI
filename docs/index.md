# TetrisRL

TetrisRL explores training a reinforcement learning agent to play Tetris directly from pixel observations. We build a complete end-to-end AI pipeline using PPO and convolutional neural networks, including training, evaluation, and gameplay video analysis. The project focuses on understanding learning dynamics in pixel-based reinforcement learning environments.

---

## Project Overview

This project investigates how an RL agent can learn Tetris strategies from visual input without handcrafted rules. The agent interacts with the ALE Tetris environment and improves its gameplay through trial and error.

Key goals:

- Build a working RL training pipeline  
- Analyze learning behavior over time  
- Evaluate both quantitative metrics and gameplay behavior  
- Study challenges in pixel-based reinforcement learning  

---

## Demo / Screenshots
![Training screenshot](images/screenshots.png)


---

## Approach

We train an agent using **Proximal Policy Optimization (PPO)** with a convolutional neural network policy.


---

## Results

---

## Resources

---


Source code: https://github.com/medhab123/NeuroScan_AI

Reports:

- [Proposal](proposal.html)
- [Status](status.html)
- [Final](final.html)
